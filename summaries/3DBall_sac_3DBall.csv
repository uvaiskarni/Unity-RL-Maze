Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Losses/Q1 Loss,Losses/Q2 Loss,Policy/Entropy Coeff,Policy/Learning Rate,Is Training
12000,1.347015,18.2064,1.4657708,0.8200320622477776,0.8200320622477776,0.18115404,-1.2504743,0.0757503,0.0767876,0.4205052,0.00029999999,1.0
24000,1.3272278,17.542503863987637,2.7102296,0.755332326133616,0.755332326133616,0.15499008,-2.5427072,0.059584968,0.06071967,0.2945231,0.00029999999,1.0
36000,1.2362089,19.416666666666668,2.7066164,0.9399659834345993,0.9399659834345993,0.11450269,-2.6092062,0.043344073,0.048513327,0.20687623,0.0003,1.0
48000,1.0430398,36.743034055727556,2.9242241,2.6130031651756713,2.6130031651756713,0.093741305,-2.6552432,0.03719369,0.041088752,0.1452802,0.00029999999,1.0
60000,0.8211481,659.75,4.308424,56.730008935928346,56.730008935928346,0.05880217,-4.0312157,0.023165325,0.025340892,0.10687878,0.00029999996,1.0
72000,0.7948409,999.0,5.6708875,100.00001525878906,100.00001525878906,0.0127695985,-5.5318294,0.003923463,0.004102535,0.07755429,0.00029999996,1.0
84000,0.85756516,999.0,6.2475142,100.00001525878906,100.00001525878906,0.004474579,-6.209258,0.0010131949,0.0010252378,0.0543706,0.00029999996,1.0
96000,0.78988445,802.8666666666667,6.623387,100.00001525878906,100.00001525878906,0.001999264,-6.6146255,0.00039956457,0.00040081632,0.03800767,0.00029999996,1.0
108000,0.6997757,999.0,6.28508,80.16667888959249,80.16667888959249,0.0035860573,-6.884798,0.0010500711,0.0014387786,0.026610652,0.00029999996,1.0
120000,0.5876042,999.0,7.121244,100.00001525878906,100.00001525878906,0.0018281293,-7.119253,0.000610796,0.0005870693,0.018702278,0.00029999996,1.0
